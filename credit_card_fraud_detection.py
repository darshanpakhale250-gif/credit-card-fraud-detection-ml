# -*- coding: utf-8 -*-
"""credit card fraud detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10TQNW0yWH6axW_Yqn58dJ68-x7IOzX8I
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/creditcard.csv.crdownload')
df

'''1. Load the dataset using the pandas module.
2. Perform missing value analysis on the dataset.
3. From the dataset, calculate the number of genuine transactions, number of
fraud transactions and the percentage of fraud transactions.
4. Using the visualization module, visualize the genuine and fraudulent
transactions using a bar graph.
5. Using the Standard Scaler module, normalize the amount column and
store the new values in the NormalizedAmount column.
6. Split the dataset in train and test set and have a 70:30 split ratio for the
model.
7. Now use a decision tree and random forest model for training on top of the
train set.
8. Compare the predictions of both models using predict().
9. Compare the accuracy of both models using score().
10. Check the performance matrix of both models and compare which
model is having the highest performance.'''

df.isnull().sum().sum()
df.dropna(inplace=True)

df.shape

df.isnull().sum().sum()

'''3. From the dataset, calculate the number of genuine transactions, number of
fraud transactions and the percentage of fraud transactions.
4. Using the visualization module, visualize the genuine and fraudulent
transactions using a bar graph.'''
df

fig = plt.figure(figsize=(10,6))
counts = df['Class'].value_counts()
plt.bar( ['Genuine (0)', 'Fraud (1)'] ,counts ,  color = ['green' , 'red'] )
plt.xlabel('Class')
plt.ylabel('Count')
plt.title('Genuine vs Fraudulent Transactions')
plt.show()

import matplotlib.pyplot as plt

fig = plt.figure(figsize=(10,6))
counts = df['Class'].value_counts()

# âœ… x = labels, y = values
plt.bar(['Genuine (0)', 'Fraud (1)'], counts, color=['green', 'red'])
plt.xlabel('Class')
plt.ylabel('Count')
plt.title('Genuine vs Fraudulent Transactions')
plt.show()

counts = df['Class'].value_counts()
print("Number of Genuine Transactions:", counts[0])
print("Number of Fraudulent Transactions:", counts[1])

fraud_percentage = (counts[1] / counts.sum()) * 100
print(f"Percentage of Fraudulent Transactions: {fraud_percentage:.4f}%")

'''5. Using the Standard Scaler module, normalize the amount column and
store the new values in the NormalizedAmount column.
6. Split the dataset in train and test set and have a 70:30 split ratio for the
model.
7. Now use a decision tree and random forest model for training on top of the
train set.
8. Compare the predictions of both models using predict().
9. Compare the accuracy of both models using score().
10. Check the performance matrix of both models and compare which
model is having the highest performance.'''

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

df['NormalizedAmount'] = scaler.fit_transform(df[['Amount']])

print(df[['Amount', 'NormalizedAmount']].head())

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

from sklearn.model_selection import train_test_split

# Features (X) and target (y)
X = df.drop(['Class'], axis=1)
y = df['Class']

# 70% training and 30% testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train)

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

y_pred_dt = dt.predict(X_test)
y_pred_rf = rf.predict(X_test)

dt_accuracy = dt.score(X_test, y_test)
rf_accuracy = rf.score(X_test, y_test)

print("Decision Tree Accuracy:", dt_accuracy)
print("Random Forest Accuracy:", rf_accuracy)

from sklearn.metrics import confusion_matrix, classification_report

# Decision Tree
print("Decision Tree Performance:")
print(confusion_matrix(y_test, y_pred_dt))
print(classification_report(y_test, y_pred_dt))

# Random Forest
print("\nRandom Forest Performance:")
print(confusion_matrix(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

